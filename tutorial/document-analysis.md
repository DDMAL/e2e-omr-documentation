---
layout: default
title: Document Analysis Tutorial
parent: OMR Tutorial
nav_order: 1
---

*Note: This tutorial uses [CDN-Mlr 073](https://archive.org/details/McGillLibrary-rbsc_ms-medieval-073-18802).*

# Image Layering

It's usually necessary to create a new model to split images into layers.
This can be done using [Pixel.js]({{site.baseurl}}/overview/document-analysis#pixeljs) or a desktop program like [Pixelmator](http://www.pixelmator.com/).
This process is time consuming and can be sped up if you have a model already
trained on a similar manuscript.
In this case, [models from the Salzinnes manuscript](https://github.com/DDMAL/Calvo-classifier/tree/develop/Models/01-square-notation/02-three-pages-val-acc-20-epochs/models) can be used.

In this example we are using pages 40, 230, and 176 from CDN-Mlr 073. The layers of these three images were created
using Pixelmator, exported as RGBA PNG images with parts of the image not in each layer made transparent,
and then loaded into Pixel.js to create the background and
selected regions layers. These genreated layers are necessary for
model training in Rodan.
Additionally, all layers from pixel were exported as masks by setting the
generate masks setting to "true".

The files were then combined using [Image Magick](https://imagemagick.org).
This is necessary because the [Patchwise Trainer]({{site.baseurl}}/overview/document-analysis#patchwise-trainer)
can only receive one image and its layers. The only way to train on multiple pages
is to combine them all into a single image and do the same for each type of layer.
The more layered pages that are provided to the Patchwise Trainer, the more data
it has to train on to segment the document into the background, music symbols, staff lines,
and text layers.

The dimensions of the files differed slightly, so background values to fill gaps
needed to be specified. The full images were
taken with a black background, and so "black" was used there. For the masks,
the keyword "none" was used to fill any gaps with transparent pixels.
So, for example with the full images:
```bash
convert -background black _A_15th_century_Italian_antiphonal___manuscript__0_40_0.jpg \
_A_15th_century_Italian_antiphonal___manuscript__0_230_0.jpg \
_A_15th_century_Italian_antiphonal___manuscript__0_176_0.jpg -append 40-230-176.jpg
```
Similarly for the text layers:
```bash
convert -background none _A_15th_century_Italian_antiphonal___manuscript__0_40_Text.png \
_A_15th_century_Italian_antiphonal___manuscript__0_230_Text.png \
_A_15th_century_Italian_antiphonal___manuscript__0_176_Text.png -append 40-230-175-Text.png
```
<figure markdown="1">
![Combined Image of Neume Layers]({{site.baseurl}}/assets/40-230_Neumes.png){:width="275"}
<figcaption>
Combined Image of Neume Layers
</figcaption>
</figure>

After experimenting with the training, it was determined the images needed to be
resized. This is because the models generated by the Patchwise Trainer yield better results
with lower dimensions (e.g., 4938x6380 px). The images were resized to 52.2% of the original
size by using the following command:
```bash
convert 40-230-176.jpg -resize 52.2% 40-230-176-Resized.jpg
```

These combined and resized files were uploaded back to Rodan for the next step.

# Model Training

Once the images and layers to use have been combined, the [Patchwise Trainer]({{site.baseurl}}/overview/document-analysis#hpc-patchwise-trainer) can be used
to generate new models.
For larger images (especially when combined), it may
be necessary to use
the HPC (High Perfomance Computing) job which dispatches the file to
the Cedar cluster of Compute Canada.

We will use this for our example with the following settings:

* Maximum Time: 0-12:00
* Maximum number of samples per label: 20000
* CPUs: 6
* Maximum number of training epochs: 15
* Maximum memory (MB): 250000
* Patch width: 256
* Patch height: 256

# Layer Extraction of Another Page

After testing that the models work on pages that they were trained on (e.g., page 176)
it is time to use them on another page from the same manuscript. Here,
page 123 of CDN-Mlr 073 is used. The [Fast Pixelwise Classifier]({{site.baseurl}}/overview/document-anlysis#fast-pixelwise-classifier)
job is run on the page scaled down to 52.2% of the original size with the default settings.
The reduction of page dimensions is necessary to obtain the best results since the models used by the classifier
were trained on the same smaller dimensions.
Three of the layers generated &mdash; music symbols, staff lines, and text &mdash; are used in future steps.
